{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default of Credit Card Clients Dataset\n",
    "Description: This dataset contains 30,000 cases of default payments in Taiwan.\n",
    "\n",
    "Goal:The goal of this project is to design and implement an Artifical Neural Network to classifiy if a credit card client is credible or not-credible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Information\n",
    "Number of Instances: 30000\n",
    "\n",
    "Missing Values: N/A\n",
    "\n",
    "Attributed Characteristic Types: Integers, Reals\n",
    "\n",
    "Number of Variables: 23\n",
    "\n",
    "X1: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit. \n",
    "\n",
    "X2: Gender (1 = male; 2 = female).\n",
    "\n",
    "X3: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others). \n",
    "\n",
    "X4: Marital status (1 = married; 2 = single; 3 = others). \n",
    "\n",
    "X5: Age (year). \n",
    "\n",
    "X6 - X11: History of past payment. We tracked the past monthly payment records (from April to September, 2005) as follows: X6 = the repayment status in September, 2005; X7 = the repayment status in August, 2005; . . .;X11 = the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above. \n",
    "\n",
    "X12-X17: Amount of bill statement (NT dollar). X12 = amount of bill statement in September, 2005; X13 = amount of bill statement in August, 2005; . . .; X17 = amount of bill statement in April, 2005.\n",
    "\n",
    "X18-X23: Amount of previous payment (NT dollar). X18 = amount paid in September, 2005; X19 = amount paid in August, 2005; . . .;X23 = amount paid in April, 2005. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>X19</th>\n",
       "      <th>X20</th>\n",
       "      <th>X21</th>\n",
       "      <th>X22</th>\n",
       "      <th>X23</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>LIMIT_BAL</td>\n",
       "      <td>SEX</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>MARRIAGE</td>\n",
       "      <td>AGE</td>\n",
       "      <td>PAY_0</td>\n",
       "      <td>PAY_2</td>\n",
       "      <td>PAY_3</td>\n",
       "      <td>PAY_4</td>\n",
       "      <td>PAY_5</td>\n",
       "      <td>...</td>\n",
       "      <td>BILL_AMT4</td>\n",
       "      <td>BILL_AMT5</td>\n",
       "      <td>BILL_AMT6</td>\n",
       "      <td>PAY_AMT1</td>\n",
       "      <td>PAY_AMT2</td>\n",
       "      <td>PAY_AMT3</td>\n",
       "      <td>PAY_AMT4</td>\n",
       "      <td>PAY_AMT5</td>\n",
       "      <td>PAY_AMT6</td>\n",
       "      <td>default payment next month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X1   X2         X3        X4   X5     X6     X7     X8     X9  \\\n",
       "ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4   \n",
       "1       20000    2          2         1   24      2      2     -1     -1   \n",
       "2      120000    2          2         2   26     -1      2      0      0   \n",
       "3       90000    2          2         2   34      0      0      0      0   \n",
       "4       50000    2          2         1   37      0      0      0      0   \n",
       "\n",
       "      X10             ...                    X15        X16        X17  \\\n",
       "ID  PAY_5             ...              BILL_AMT4  BILL_AMT5  BILL_AMT6   \n",
       "1      -2             ...                      0          0          0   \n",
       "2       0             ...                   3272       3455       3261   \n",
       "3       0             ...                  14331      14948      15549   \n",
       "4       0             ...                  28314      28959      29547   \n",
       "\n",
       "         X18       X19       X20       X21       X22       X23  \\\n",
       "ID  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6   \n",
       "1          0       689         0         0         0         0   \n",
       "2          0      1000      1000      1000         0      2000   \n",
       "3       1518      1500      1000      1000      1000      5000   \n",
       "4       2000      2019      1200      1100      1069      1000   \n",
       "\n",
       "                             Y  \n",
       "ID  default payment next month  \n",
       "1                            1  \n",
       "2                            1  \n",
       "3                            0  \n",
       "4                            0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Read raw data from excel spread sheet\n",
    "raw_data = pd.read_excel('default of credit card clients.xls')\n",
    "raw_data.head() #display first 5 rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Convert the excel spreadsheet data into a numpy array.Note: Ignore the first row which are labels\n",
    "raw_data_np = raw_data[1:].as_matrix()\n",
    "\n",
    "#Split up training data and test data(80% = training data, 20% = test data)\n",
    "#Scale the data using scikit learns StandardScaler\n",
    "training_data = raw_data_np[:24000, :-1].astype(np.float32) #first 80% of data is for training(set type to float32)\n",
    "training_data_labels = np.reshape(raw_data_np[:24000, -1], (-1, 1)) #Labels for the training set\n",
    "\n",
    "scale_data = StandardScaler() #Normalize/center the data\n",
    "training_data_scaled = scale_data.fit_transform(training_data) \n",
    "\n",
    "testing_data = raw_data_np[24000:, :-1].astype(np.float32) #20% of the data is for testing(set type to float32)\n",
    "testing_data_labels = np.reshape(raw_data_np[24000:, -1], (-1, 1))\n",
    "testing_data_scaled = scale_data.transform(testing_data) #Normailze/center the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of Deep Neural Network Model\n",
    "\n",
    "The Deep Neural Network Model implemented in this project is a binary classifier.The Architecture of the DNN consist of an input layer(pass-through layer), 4 hidden layers, and an output layer. The size of the input layer is 23, which is the number of features to given. The 4 hidden layers gradually decrease in number of neurons. In each hidden layer, the ELU activation function is used.The output layer has a single output, which is a probability in the range [0, 1] produced from the a sigmoid logistic regression function.\n",
    "\n",
    "For normalization of each layer's inputs, Batch Normalization is used. \n",
    "\n",
    "Mini-batch Gradient Descent is used to train the model with the help of backpropagation. The Logistic Cost Function is used to measure the cost and compute the gradients needed for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization\n",
    "\n",
    "Mean of batch: $\\mu _{b}=\\frac{1}{m_{b}}\\sum_{i=1}^{m_{b}}x^{(i)}$\n",
    "\n",
    "Standard Deviation of Batch: $\\sigma_{b}^2=\\frac{1}{m_{b}}\\sum_{i=1}^{m_{b}}(x^{(i)}-\\mu_{b})^2$\n",
    "\n",
    "Normalization: ${\\hat{x}^{(i)}}=\\frac{x^{(i)}-\\mu_{b}}{\\sqrt{\\sigma_{b}^2 + \\varepsilon }}$\n",
    "\n",
    "Scale and shift: $z^{(i)}=y\\hat{x}^{(i)}+b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "num_inputs = 23\n",
    "num_hidden_1 = 23 #Number of neurons in 1st hidden layer\n",
    "num_hidden_2 = 20 #Number of neurons in 2nd hidden layer \n",
    "num_hidden_3 = 15 #Number of neurons in 3rd hidden layer\n",
    "num_hidden_4 = 10 #Number of neurons in 4th hidden layer\n",
    "num_outputs = 1    \n",
    "\n",
    "#define place holders for input data to be used for mini-batch\n",
    "X = tf.placeholder(tf.float32, shape=(None, num_inputs), name=\"X\") #Input data\n",
    "y = tf.placeholder(tf.int32, shape=(None, num_outputs), name=\"y\") #Output(target) data\n",
    "\n",
    "#A placeholder to tell batch normalization whether to compute mean and standard deviation off of mini-batches or\n",
    "#entire set of training data.\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "with tf.name_scope(\"dnn_model\"):\n",
    "    #Hidden layer 1\n",
    "    hidden_1 = tf.layers.dense(X, num_hidden_1, activation=None, name=\"hidden_1\") \n",
    "    bn_1 = tf.layers.batch_normalization(hidden_1, training=training, momentum=0.99) #batch normalization\n",
    "    bn_1_activation = tf.nn.relu(bn_1) #ELU activation function\n",
    "    \n",
    "    #Hidden layer 2\n",
    "    hidden_2 = tf.layers.dense(bn_1_activation, num_hidden_2, activation=None, name=\"hidden_2\") \n",
    "    bn_2 = tf.layers.batch_normalization(hidden_2, training=training, momentum=0.99) #batch normalization\n",
    "    bn_2_activation = tf.nn.relu(bn_2) #ELU activation function\n",
    "    \n",
    "    #Hidden layer 3\n",
    "    hidden_3 = tf.layers.dense(bn_2_activation, num_hidden_3, activation=None, name=\"hidden_3\") \n",
    "    bn_3 = tf.layers.batch_normalization(hidden_3, training=training, momentum=0.99) #batch normalization\n",
    "    bn_3_activation = tf.nn.relu(bn_3) #ELU activation function\n",
    "    \n",
    "    #Hidden layer 4\n",
    "    hidden_4 = tf.layers.dense(bn_3_activation, num_hidden_4, activation=None, name=\"hidden_4\") \n",
    "    bn_4 = tf.layers.batch_normalization(hidden_4, training=training, momentum=0.99) #batch normalization\n",
    "    bn_4_activation = tf.nn.relu(bn_4) #ELU activation function\n",
    "    \n",
    "    #Output layer\n",
    "    #For the activation of the last layer, a sigmoid function is used to output a probability between 0 and 1\n",
    "    output = tf.layers.dense(bn_4_activation, num_outputs, name=\"output\")\n",
    "    bn_output_logits = tf.layers.batch_normalization(output, training=training, momentum=0.99)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the probability outputted is > 0.5(50%), then the prediction is True(=1)...else it is False(=0)\n",
    "probability_thresh = tf.constant(0.5, dtype=tf.float32, name=\"logistic_probability_thresh\")\n",
    "\n",
    "with tf.name_scope(\"model_loss\"):\n",
    "    #Sigmoid Logistic Regression Function\n",
    "    probabilities = tf.nn.sigmoid(bn_output_logits, name=\"sigmoid_activation\")\n",
    "    \n",
    "    #Logistic regression model prediction\n",
    "    log_reg_pred = probabilities >= probability_thresh\n",
    "    \n",
    "    #Cost function\n",
    "    loss = tf.losses.log_loss(labels=y, predictions=probabilities)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "with tf.name_scope(\"train\"):\n",
    "    #Use gradient descent to reduce loss\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    #computes gradients and applys gradients\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    #Calculate accuracy of values correctly classified\n",
    "    correct = tf.equal((tf.cast(y, tf.int32)), tf.cast(log_reg_pred,tf.int32))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to retreive mini-batchs\n",
    "def get_mini_batch(X, y, current_batch_num, batch_numbers):\n",
    "    '''\n",
    "    Get mini-batch of input data and labels. Each dataset will be split in n number of batches, and \n",
    "    current batch number will select the necessary mini-batch from the subsets of the split.\n",
    "    \n",
    "    Parameters:\n",
    "        X: Input dataset to be fed for training into the DNN\n",
    "        y: The target dataset for the input data used to train the DNN on\n",
    "        current_batch_num: The current iteration in training to select a new mini-batch.\n",
    "        batch_numbers: The overall number of batchs to split the whole dataset into\n",
    "    \n",
    "    Returns:\n",
    "        batch_X: The mini-batch for input training data\n",
    "        batch_y: The mini-batch for target training data\n",
    "    '''\n",
    "    X, y= np.asarray(X), np.asarray(y)\n",
    "    batch_X = np.split(X, batch_numbers)[current_batch_num]\n",
    "    batch_y = np.split(y, batch_numbers)[current_batch_num]\n",
    "    return batch_X, batch_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "|Testing Accuracy: 0.80483335 |\n",
      "|Training Log Loss: 0.5371692 |\n",
      "Epoch: 1\n",
      "|Testing Accuracy: 0.8156667 |\n",
      "|Training Log Loss: 0.49723056 |\n",
      "Epoch: 2\n",
      "|Testing Accuracy: 0.817 |\n",
      "|Training Log Loss: 0.47866413 |\n",
      "Epoch: 3\n",
      "|Testing Accuracy: 0.82016665 |\n",
      "|Training Log Loss: 0.46989128 |\n",
      "Epoch: 4\n",
      "|Testing Accuracy: 0.82133335 |\n",
      "|Training Log Loss: 0.4651575 |\n",
      "Epoch: 5\n",
      "|Testing Accuracy: 0.8221667 |\n",
      "|Training Log Loss: 0.46225142 |\n",
      "Epoch: 6\n",
      "|Testing Accuracy: 0.822 |\n",
      "|Training Log Loss: 0.4602183 |\n",
      "Epoch: 7\n",
      "|Testing Accuracy: 0.82266665 |\n",
      "|Training Log Loss: 0.45865756 |\n",
      "Epoch: 8\n",
      "|Testing Accuracy: 0.8236667 |\n",
      "|Training Log Loss: 0.4573743 |\n",
      "Epoch: 9\n",
      "|Testing Accuracy: 0.82266665 |\n",
      "|Training Log Loss: 0.4563041 |\n",
      "Epoch: 10\n",
      "|Testing Accuracy: 0.82383335 |\n",
      "|Training Log Loss: 0.4553336 |\n",
      "Epoch: 11\n",
      "|Testing Accuracy: 0.8236667 |\n",
      "|Training Log Loss: 0.4544598 |\n",
      "Epoch: 12\n",
      "|Testing Accuracy: 0.82533336 |\n",
      "|Training Log Loss: 0.4536376 |\n",
      "Epoch: 13\n",
      "|Testing Accuracy: 0.82566667 |\n",
      "|Training Log Loss: 0.45287687 |\n",
      "Epoch: 14\n",
      "|Testing Accuracy: 0.8268333 |\n",
      "|Training Log Loss: 0.45215967 |\n",
      "Epoch: 15\n",
      "|Testing Accuracy: 0.82666665 |\n",
      "|Training Log Loss: 0.4514988 |\n",
      "Epoch: 16\n",
      "|Testing Accuracy: 0.8261667 |\n",
      "|Training Log Loss: 0.4508791 |\n",
      "Epoch: 17\n",
      "|Testing Accuracy: 0.82633334 |\n",
      "|Training Log Loss: 0.4503039 |\n",
      "Epoch: 18\n",
      "|Testing Accuracy: 0.827 |\n",
      "|Training Log Loss: 0.44974545 |\n",
      "Epoch: 19\n",
      "|Testing Accuracy: 0.82733333 |\n",
      "|Training Log Loss: 0.44920802 |\n",
      "Epoch: 20\n",
      "|Testing Accuracy: 0.82666665 |\n",
      "|Training Log Loss: 0.4487024 |\n",
      "Epoch: 21\n",
      "|Testing Accuracy: 0.82666665 |\n",
      "|Training Log Loss: 0.44821876 |\n",
      "Epoch: 22\n",
      "|Testing Accuracy: 0.8271667 |\n",
      "|Training Log Loss: 0.44773984 |\n",
      "Epoch: 23\n",
      "|Testing Accuracy: 0.82766664 |\n",
      "|Training Log Loss: 0.44730815 |\n",
      "Epoch: 24\n",
      "|Testing Accuracy: 0.828 |\n",
      "|Training Log Loss: 0.44688684 |\n",
      "Epoch: 25\n",
      "|Testing Accuracy: 0.8285 |\n",
      "|Training Log Loss: 0.44646606 |\n",
      "Epoch: 26\n",
      "|Testing Accuracy: 0.8293333 |\n",
      "|Training Log Loss: 0.4460391 |\n",
      "Epoch: 27\n",
      "|Testing Accuracy: 0.82916665 |\n",
      "|Training Log Loss: 0.4456381 |\n",
      "Epoch: 28\n",
      "|Testing Accuracy: 0.82916665 |\n",
      "|Training Log Loss: 0.44527426 |\n",
      "Epoch: 29\n",
      "|Testing Accuracy: 0.82916665 |\n",
      "|Training Log Loss: 0.4449034 |\n",
      "Epoch: 30\n",
      "|Testing Accuracy: 0.829 |\n",
      "|Training Log Loss: 0.44454306 |\n",
      "Epoch: 31\n",
      "|Testing Accuracy: 0.8293333 |\n",
      "|Training Log Loss: 0.44420785 |\n",
      "Epoch: 32\n",
      "|Testing Accuracy: 0.82883334 |\n",
      "|Training Log Loss: 0.44386914 |\n",
      "Epoch: 33\n",
      "|Testing Accuracy: 0.8283333 |\n",
      "|Training Log Loss: 0.4435747 |\n",
      "Epoch: 34\n",
      "|Testing Accuracy: 0.82783335 |\n",
      "|Training Log Loss: 0.443251 |\n",
      "Epoch: 35\n",
      "|Testing Accuracy: 0.8275 |\n",
      "|Training Log Loss: 0.44295242 |\n",
      "Epoch: 36\n",
      "|Testing Accuracy: 0.8275 |\n",
      "|Training Log Loss: 0.44266146 |\n",
      "Epoch: 37\n",
      "|Testing Accuracy: 0.8275 |\n",
      "|Training Log Loss: 0.44240117 |\n",
      "Epoch: 38\n",
      "|Testing Accuracy: 0.827 |\n",
      "|Training Log Loss: 0.44210503 |\n",
      "Epoch: 39\n",
      "|Testing Accuracy: 0.8275 |\n",
      "|Training Log Loss: 0.44183952 |\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 40 #Number of epochs\n",
    "batch_size = 100 #Batch size\n",
    "\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS) #extra operations to be computed during training for batch normalization\n",
    "init = tf.global_variables_initializer() #Node to initialize all variables\n",
    "batch_numbers = int(training_data_scaled.shape[0] / batch_size) #Number of batchs to train on whole data set\n",
    "\n",
    "#loss data list to plot\n",
    "log_loss_plot = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run() #Initialize global variables for the session\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(batch_numbers):\n",
    "            \n",
    "            #Get the current mini batch for the given iteration to compute gradients\n",
    "            X_batch, y_batch = get_mini_batch(training_data_scaled, training_data_labels, iteration, batch_numbers)\n",
    "            \n",
    "            #Train the model on current mini batch\n",
    "            sess.run([training_op, extra_update_ops], feed_dict={training:True, X:X_batch, y:y_batch})\n",
    "            \n",
    "            #Every 10 iterations, save the Logarithmic Loss to be plotted on the cost function graph\n",
    "            if(iteration % 10 == 0):\n",
    "                log_loss_plot.append(loss.eval(feed_dict={X:training_data_scaled, y:training_data_labels}))\n",
    "        \n",
    "        #Calculate the current accuracy at epoch n after each training step over the whole training set\n",
    "        accuracy_val = accuracy.eval(feed_dict={X:testing_data_scaled, y:testing_data_labels})\n",
    "        \n",
    "        #Compute the loss of the training set\n",
    "        log_loss = loss.eval(feed_dict={X:training_data_scaled, y:training_data_labels})\n",
    "        print(\"Epoch:\", epoch)\n",
    "        print(\"|Testing Accuracy:\", accuracy_val, \"|\")\n",
    "        print(\"|Training Log Loss:\", log_loss, \"|\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(log_loss_plot)\n",
    "plt.ylabel(\"Log loss(All Training)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
